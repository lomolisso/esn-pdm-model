{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESN-PdM Framework ML models\n",
    "This notebook contains the implementation of the ESN-PdM framework's machine learning models. These models are developed using the `tensorflow` library and trained with a dataset specifically generated for this project. The data is located in the `dataset` folder of this repository and consists of several files, each corresponding to one of the four classes the models are trained to predict. The data was generated using a BMI270 IMU and an ESP32, hence the features include the raw accelerometer and gyroscope readings from the IMU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports, Constants and Converters\n",
    "First, we import the necessary libraries and define some constants and converters that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Disable logs except for errors\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "INPUT_DATA_PATH = 'datos/'\n",
    "\n",
    "LABELS = {\n",
    "    \"Good\": 0,\n",
    "    \"Acceptable\": 1,\n",
    "    \"Unacceptable\": 2,\n",
    "    \"Bad\": 3\n",
    "}\n",
    "\n",
    "# --- Accelerometer Constants ---\n",
    "G_MS2 = 9.80665\n",
    "MAX_INT_VALUE_SENSOR = 32768.0\n",
    "ACC_RAW_TO_MS2 = (G_MS2 / MAX_INT_VALUE_SENSOR)\n",
    "SENSOR_ACC_RANGE = 2 # 8g\n",
    "\n",
    "# --- Gyroscope Constants ---\n",
    "SENSOR_GYR_RANGE = 250.0\n",
    "PI = 3.14159265359\n",
    "GYR_RAW_TO_RADS = (PI / 180.0) / MAX_INT_VALUE_SENSOR\n",
    "\n",
    "# --- Converters ---\n",
    "convert_raw_acc_to_ms2 = lambda raw: (pow(2, SENSOR_ACC_RANGE + 1) * ACC_RAW_TO_MS2) * raw\n",
    "convert_raw_gyr_to_rads = lambda raw: SENSOR_GYR_RANGE * GYR_RAW_TO_RADS * raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing\n",
    "Next, we load the data and preprocess it. The data is loaded from the files in the `dataset` folder and preprocessed to be used in the models. The preprocessing steps include cleaning null values, converting the raw data to the appropriate format and normalizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 572331 entries, 0 to 572330\n",
      "Data columns (total 10 columns):\n",
      " #   Column     Non-Null Count   Dtype         \n",
      "---  ------     --------------   -----         \n",
      " 0   id         572331 non-null  int64         \n",
      " 1   sensor     572331 non-null  int64         \n",
      " 2   acc_x      572331 non-null  float32       \n",
      " 3   acc_y      572331 non-null  float32       \n",
      " 4   acc_z      572331 non-null  float32       \n",
      " 5   gyro_x     572331 non-null  float32       \n",
      " 6   gyro_y     572331 non-null  float32       \n",
      " 7   gyro_z     572331 non-null  float32       \n",
      " 8   timestamp  572331 non-null  datetime64[ns]\n",
      " 9   label      572331 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float32(6), int64(3)\n",
      "memory usage: 30.6 MB\n",
      "None\n",
      "                  id         sensor          acc_x          acc_y  \\\n",
      "count  572331.000000  572331.000000  572331.000000  572331.000000   \n",
      "mean    33363.663066       1.501467      -0.274573       0.085277   \n",
      "min      1624.000000       1.000000     -20.563799     -26.352978   \n",
      "25%     17750.000000       1.000000      -1.970428      -0.883460   \n",
      "50%     32265.000000       2.000000      -0.284910      -0.014365   \n",
      "75%     46781.000000       2.000000       1.307234       0.907402   \n",
      "max     84800.000000       2.000000      20.441694      20.092140   \n",
      "std     18709.204719       0.499998       5.009295       1.478782   \n",
      "\n",
      "               acc_z         gyro_x         gyro_y         gyro_z  \\\n",
      "count  572331.000000  572331.000000  572331.000000  572331.000000   \n",
      "mean       -4.837997       0.002267      -0.019604       0.001179   \n",
      "min       -45.635880      -3.561312      -4.363323      -1.974201   \n",
      "25%        -9.483433      -0.179497      -3.234010      -0.074835   \n",
      "50%        -4.908113       0.003862      -0.041013       0.001065   \n",
      "75%        -0.495600       0.170975       3.214968       0.080960   \n",
      "max        41.144356       4.339754       4.363190       2.530402   \n",
      "std        10.038818       0.387945       3.200114       0.142176   \n",
      "\n",
      "                           timestamp          label  \n",
      "count                         572331  572331.000000  \n",
      "mean   2021-08-19 16:07:16.473596160       1.460162  \n",
      "min              2021-08-19 13:21:07       0.000000  \n",
      "25%              2021-08-19 15:19:42       1.000000  \n",
      "50%              2021-08-19 16:18:56       1.000000  \n",
      "75%              2021-08-19 17:19:11       2.000000  \n",
      "max              2021-08-19 18:06:16       3.000000  \n",
      "std                              NaN       1.026118  \n"
     ]
    }
   ],
   "source": [
    "with open(INPUT_DATA_PATH + 'column_names.json') as f:\n",
    "    column_names = json.load(f)\n",
    "\n",
    "labeled_data_frames = {l: [] for l in LABELS.values()}\n",
    "for filename in os.listdir(INPUT_DATA_PATH):\n",
    "    for label in LABELS.values():\n",
    "        if filename.startswith(str(label)) and filename.endswith('.csv'):\n",
    "            df = pd.read_csv(INPUT_DATA_PATH + filename, names=column_names, sep=';')\n",
    "            \n",
    "            # Convert the timestamp column to a datetime object\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            \n",
    "            # Create a mask for rows where acc_x, acc_y, and acc_z are all 0\n",
    "            mask_acc_zero = (df['acc_x'] == 0) & (df['acc_y'] == 0) & (df['acc_z'] == 0)\n",
    "\n",
    "            # Create a mask for rows where gyro_x, gyro_y, and gyro_z are all 0\n",
    "            mask_gyro_zero = (df['gyro_x'] == 0) & (df['gyro_y'] == 0) & (df['gyro_z'] == 0)\n",
    "\n",
    "            # Combine the masks to identify rows where either condition is true\n",
    "            mask_either_zero = mask_acc_zero | mask_gyro_zero\n",
    "\n",
    "            # Filter out the rows from the DataFrame\n",
    "            df = df[~mask_either_zero]\n",
    "\n",
    "            # Convert the raw accelerometer data to m/s^2\n",
    "            df['acc_x'] = df['acc_x'].apply(convert_raw_acc_to_ms2).astype(\"float32\")\n",
    "            df['acc_y'] = df['acc_y'].apply(convert_raw_acc_to_ms2).astype(\"float32\")\n",
    "            df['acc_z'] = df['acc_z'].apply(convert_raw_acc_to_ms2).astype(\"float32\")\n",
    "\n",
    "            # Convert the raw gyroscope data to rad/s\n",
    "            df['gyro_x'] = df['gyro_x'].apply(convert_raw_gyr_to_rads).astype(\"float32\")\n",
    "            df['gyro_y'] = df['gyro_y'].apply(convert_raw_gyr_to_rads).astype(\"float32\")\n",
    "            df['gyro_z'] = df['gyro_z'].apply(convert_raw_gyr_to_rads).astype(\"float32\")\n",
    "            \n",
    "            labeled_data_frames[label].append(df)\n",
    "\n",
    "dataframes = {label: pd.concat(data_frames) for label, data_frames in labeled_data_frames.items()}\n",
    "\n",
    "# Make a copy of all the dataframes, add a label column, and concatenate them into a single dataframe\n",
    "labeled_data = pd.concat([df.assign(label=label) for label, df in dataframes.items()])\n",
    "labeled_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print info and overall stats about the dataset\n",
    "print(labeled_data.info())\n",
    "print(labeled_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Generation and Data Splitting\n",
    "After preprocessing the data, we generate sequences that will be used for training the models. These sequences are created by filling a buffer with `SEG_LENGTH` contiguous readings. Once the sequences are generated, we split the data into training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences: (11444, 50, 6)\n",
      "Labels: (11444,)\n"
     ]
    }
   ],
   "source": [
    "SEQ_LENGTH = 50\n",
    "\n",
    "# crop dataframes to a number of rows that is a multiple of SEQ_LENGTH\n",
    "for label, data in dataframes.items():\n",
    "    dataframes[label] = data.iloc[:len(data) - len(data) % SEQ_LENGTH]\n",
    "\n",
    "# Crear secuencias y etiquetas\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "# Create sequences and labels\n",
    "for label, data in dataframes.items():\n",
    "    for i in range(0, len(data), SEQ_LENGTH):\n",
    "        seq = data.iloc[i:i + SEQ_LENGTH]\n",
    "        sequences.append(seq[['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']].values)\n",
    "        labels.append(label)\n",
    "\n",
    "sequences, labels = np.array(sequences), np.array(labels)\n",
    "\n",
    "# Print the number of sequences to be fed into the model\n",
    "print(f\"Sequences: {sequences.shape}\")\n",
    "print(f\"Labels: {labels.shape}\")\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(sequences, labels, test_size=0.4, random_state=random.randint(0, 100))\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random.randint(0, 100))\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(LABELS))\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=len(LABELS))\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "We define the model architecture, which consists of parallel `LSTM` and `Conv1D` layers followed by fully connected layers. The RNN layer operates on the sequence in the temporal domain, while the CNN layer operates on the sequence in the frequency domain by transforming the signal through `FFT`. This structure aims to capture both the temporal and spatial features of the data. The model is compiled using the Adam optimizer and the categorical cross-entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_model():\n",
    "    # Input layer\n",
    "    inputs = tf.keras.layers.Input(shape=(SEQ_LENGTH, 6))\n",
    "\n",
    "    # Convolutional layers\n",
    "    conv1 = tf.keras.layers.SeparableConv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    conv2 = tf.keras.layers.SeparableConv1D(filters=64, kernel_size=3, activation='relu', padding='same')(conv1)\n",
    "    pool = tf.keras.layers.MaxPooling1D()(conv2)\n",
    "    pool_flat = tf.keras.layers.Flatten()(pool)\n",
    "\n",
    "    # LSTM\n",
    "    lstm = tf.keras.layers.LSTM(64, return_sequences=True)(inputs)\n",
    "    lstm_flat = tf.keras.layers.Flatten()(lstm)\n",
    "\n",
    "    # Concatenation of Conv and LSTM paths\n",
    "    concat = tf.keras.layers.Concatenate()([pool_flat, lstm_flat])\n",
    "\n",
    "    # Dense layers\n",
    "    dense1 = tf.keras.layers.Dense(128, activation='relu')(concat)\n",
    "    dense2 = tf.keras.layers.Dense(64, activation='relu')(dense1)\n",
    "    dense3 = tf.keras.layers.Dense(32, activation='relu')(dense2)\n",
    "    outputs = tf.keras.layers.Dense(len(LABELS), activation='softmax')(dense3)\n",
    "\n",
    "    # Model creation\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Model\n",
    "The model to be deployed on the cloud layer of the ESN-PdM framework is trained using the training and validation sets. The model is trained for `50` epochs using mini-batches of size `32`. To avoid overfitting, we use early stopping with a patience of `5` epochs, i.e., if the validation loss does not improve for `5` consecutive epochs, the training is stopped. The model is saved to a file named `cloud_model.keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "108/108 [==============================] - 4s 26ms/step - loss: 0.3918 - accuracy: 0.8522 - val_loss: 0.1527 - val_accuracy: 0.9537\n",
      "Epoch 2/15\n",
      "108/108 [==============================] - 3s 25ms/step - loss: 0.0819 - accuracy: 0.9747 - val_loss: 0.0797 - val_accuracy: 0.9755\n",
      "Epoch 3/15\n",
      "108/108 [==============================] - 3s 25ms/step - loss: 0.0543 - accuracy: 0.9819 - val_loss: 0.0678 - val_accuracy: 0.9808\n",
      "Epoch 4/15\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.0296 - accuracy: 0.9913 - val_loss: 0.0632 - val_accuracy: 0.9825\n",
      "Epoch 5/15\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.0724 - val_accuracy: 0.9808\n",
      "Epoch 6/15\n",
      "108/108 [==============================] - 3s 25ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.1053 - val_accuracy: 0.9690\n",
      "Epoch 7/15\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.0769 - val_accuracy: 0.9830\n",
      "Epoch 8/15\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1238 - val_accuracy: 0.9773\n",
      "Epoch 9/15\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.1253 - val_accuracy: 0.9755\n",
      "72/72 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rdelaf/Documents/thesis/edge-sensor-network/esn-cloud-layer/model/venv/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Training constants\n",
    "CLOUD_MODEL_TRAIN_EPOCHS = 15\n",
    "MAX_EPOCHS_WITHOUT_IMPROVEMENT = 5\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Create the model\n",
    "cloud_model = create_model()\n",
    "\n",
    "# Compile the model\n",
    "cloud_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=MAX_EPOCHS_WITHOUT_IMPROVEMENT, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "cloud_model.fit(X_train, y_train, epochs=CLOUD_MODEL_TRAIN_EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "cloud_y_pred = cloud_model.predict(X_test)\n",
    "cloud_y_pred_classes = np.argmax(cloud_y_pred, axis=1)\n",
    "cloud_model_accuracy = np.mean(cloud_y_pred_classes == y_true)\n",
    "\n",
    "# Save the model\n",
    "cloud_model.save('cloud_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.98      0.98      0.98       517\n",
      "  Acceptable       0.98      1.00      0.99       635\n",
      "Unacceptable       0.98      0.97      0.98       748\n",
      "         Bad       0.97      0.99      0.98       389\n",
      "\n",
      "    accuracy                           0.98      2289\n",
      "   macro avg       0.98      0.98      0.98      2289\n",
      "weighted avg       0.98      0.98      0.98      2289\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[505   0   8   4]\n",
      " [  1 632   2   0]\n",
      " [  9  10 723   6]\n",
      " [  2   0   2 385]]\n",
      "Model accuracy: 0.9807776321537789\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 6)]              0         []                            \n",
      "                                                                                                  \n",
      " separable_conv1d (Separabl  (None, 50, 64)               466       ['input_1[0][0]']             \n",
      " eConv1D)                                                                                         \n",
      "                                                                                                  \n",
      " separable_conv1d_1 (Separa  (None, 50, 64)               4352      ['separable_conv1d[0][0]']    \n",
      " bleConv1D)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1  (None, 25, 64)               0         ['separable_conv1d_1[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 50, 64)               18176     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 1600)                 0         ['max_pooling1d[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 3200)                 0         ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 4800)                 0         ['flatten[0][0]',             \n",
      "                                                                     'flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  614528    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 64)                   8256      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 32)                   2080      ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 4)                    132       ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 647990 (2.47 MB)\n",
      "Trainable params: 647990 (2.47 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(\"--- Classification Report ---\")\n",
    "print(classification_report(y_true, cloud_y_pred_classes, target_names=LABELS.keys()))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"--- Confusion Matrix ---\")\n",
    "print(confusion_matrix(y_true, cloud_y_pred_classes))\n",
    "\n",
    "# Print model accuracy\n",
    "print(f\"Model accuracy: {cloud_model_accuracy}\")\n",
    "\n",
    "# Print model summary\n",
    "cloud_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gateway Model\n",
    "Unlike a cloud server, a gateway, such as the Raspberry Pi 4 used in the ESN-PdM framework, has limited computational resources. Therefore, the model deployed on the gateway layer needs to be lightweight yet accurate. To achieve this, we **fine-tune the pre-trained cloud model using pruning**. Pruning is a technique that removes less important weights from the model, reducing its size and computational complexity. During the fine-tuning process, the pruning sparsity is gradually increased from `0.50` to `0.80`. Pruning sparsity is the ratio of the number of weights zeroed out to the total number of weights in the model. In other words, after pruning, the resulting model will have 80% of its weights zeroed out.\n",
    "\n",
    "The pruned model is then converted to a TensorFlow Lite model, optimized for deployment on edge devices. Among these optimizations is **post-training quantization**, which further reduces the model's size and computational complexity by converting its parameters from 32-bit floating-point numbers to 8-bit integers. Specifically, the type of quantization used for the gateway model is **dynamic range quantization**. This type of quantization only affects the weights of the model, leaving the activations in floating-point format.\n",
    "\n",
    "The final model is saved to a file named `gateway_model.tflite`. Note that applying a standard compression algorithm, such as gzip, is necessary to fully realize the compression benefits of pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "108/108 [==============================] - 5s 29ms/step - loss: 0.3549 - accuracy: 0.8742 - val_loss: 0.2517 - val_accuracy: 0.9048\n",
      "Epoch 2/3\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1078 - accuracy: 0.9649 - val_loss: 0.1580 - val_accuracy: 0.9502\n",
      "Epoch 3/3\n",
      "108/108 [==============================] - 3s 26ms/step - loss: 0.0777 - accuracy: 0.9768 - val_loss: 0.0954 - val_accuracy: 0.9672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x305de90c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "GATEWAY_FINE_TUNE_EPOCHS = 3\n",
    "FINE_TUNE_EPOCHS_WITHOUT_IMPROVEMENT = 1\n",
    "\n",
    "num_sequences = X_train.shape[0]\n",
    "end_step = np.ceil(num_sequences / BATCH_SIZE).astype(np.int32) * GATEWAY_FINE_TUNE_EPOCHS\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.0,\n",
    "        final_sparsity=0.50,\n",
    "        begin_step=0,\n",
    "        end_step=end_step\n",
    "    )\n",
    "}\n",
    "\n",
    "callbacks = [\n",
    "  tf.keras.callbacks.EarlyStopping(\n",
    "      monitor='val_accuracy',\n",
    "      patience=FINE_TUNE_EPOCHS_WITHOUT_IMPROVEMENT,\n",
    "      restore_best_weights=False\n",
    "  ),\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "]\n",
    "\n",
    "# Load the cloud model and fine-tune it with pruning\n",
    "_loaded_cloud_model = tf.keras.models.load_model('cloud_model.keras')\n",
    "gateway_model = prune_low_magnitude(_loaded_cloud_model, **pruning_params)\n",
    "\n",
    "# Compile the model\n",
    "gateway_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "gateway_model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=GATEWAY_FINE_TUNE_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 4ms/step\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.95      0.96      0.96       517\n",
      "  Acceptable       0.99      0.99      0.99       635\n",
      "Unacceptable       0.98      0.97      0.98       748\n",
      "         Bad       0.94      0.95      0.94       389\n",
      "\n",
      "    accuracy                           0.97      2289\n",
      "   macro avg       0.97      0.97      0.97      2289\n",
      "weighted avg       0.97      0.97      0.97      2289\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[496   1   7  13]\n",
      " [  1 630   4   0]\n",
      " [  6   3 729  10]\n",
      " [ 18   0   2 369]]\n",
      "Gateway model accuracy: 0.9716033202271734\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 50, 6)]              0         []                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_separa  (None, 50, 64)               852       ['input_2[0][0]']             \n",
      " ble_conv1d_2 (PruneLowMagn                                                                       \n",
      " itude)                                                                                           \n",
      "                                                                                                  \n",
      " prune_low_magnitude_separa  (None, 50, 64)               8450      ['prune_low_magnitude_separabl\n",
      " ble_conv1d_3 (PruneLowMagn                                         e_conv1d_2[0][0]']            \n",
      " itude)                                                                                           \n",
      "                                                                                                  \n",
      " prune_low_magnitude_max_po  (None, 25, 64)               1         ['prune_low_magnitude_separabl\n",
      " oling1d_1 (PruneLowMagnitu                                         e_conv1d_3[0][0]']            \n",
      " de)                                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_lstm_1  (None, 50, 64)               36099     ['input_2[0][0]']             \n",
      "  (PruneLowMagnitude)                                                                             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_flatte  (None, 1600)                 1         ['prune_low_magnitude_max_pool\n",
      " n_2 (PruneLowMagnitude)                                            ing1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_flatte  (None, 3200)                 1         ['prune_low_magnitude_lstm_1[0\n",
      " n_3 (PruneLowMagnitude)                                            ][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_concat  (None, 4800)                 1         ['prune_low_magnitude_flatten_\n",
      " enate_1 (PruneLowMagnitude                                         2[0][0]',                     \n",
      " )                                                                   'prune_low_magnitude_flatten_\n",
      "                                                                    3[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense_  (None, 128)                  1228930   ['prune_low_magnitude_concaten\n",
      " 4 (PruneLowMagnitude)                                              ate_1[0][0]']                 \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense_  (None, 64)                   16450     ['prune_low_magnitude_dense_4[\n",
      " 5 (PruneLowMagnitude)                                              0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense_  (None, 32)                   4130      ['prune_low_magnitude_dense_5[\n",
      " 6 (PruneLowMagnitude)                                              0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense_  (None, 4)                    262       ['prune_low_magnitude_dense_6[\n",
      " 7 (PruneLowMagnitude)                                              0][0]']                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1295177 (4.94 MB)\n",
      "Trainable params: 647990 (2.47 MB)\n",
      "Non-trainable params: 647187 (2.47 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "gateway_y_pred = gateway_model.predict(X_test)\n",
    "gateway_y_pred_classes = np.argmax(gateway_y_pred, axis=1)\n",
    "gateway_model_accuracy = np.sum(y_true == gateway_y_pred_classes) / len(y_true)\n",
    "\n",
    "# Print classification report\n",
    "print(\"--- Classification Report ---\")\n",
    "print(classification_report(y_true, gateway_y_pred_classes, target_names=LABELS.keys()))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"--- Confusion Matrix ---\")\n",
    "print(confusion_matrix(y_true, gateway_y_pred_classes))\n",
    "\n",
    "# Print accuracy before tflite conversion\n",
    "print(f\"Gateway model accuracy: {gateway_model_accuracy}\")\n",
    "\n",
    "# Print the gateway model summary\n",
    "gateway_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/cv/np29wc5x57scn_0hl8328btr0000gn/T/tmpymmfptf8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/cv/np29wc5x57scn_0hl8328btr0000gn/T/tmpymmfptf8/assets\n"
     ]
    }
   ],
   "source": [
    "# Remove pruning wrappers from the pruned model\n",
    "gateway_model = tfmot.sparsity.keras.strip_pruning(gateway_model)\n",
    "\n",
    "# Make a Tensorflow Lite version of the model and save it\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(gateway_model)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "\n",
    "# Dynamic range quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  \n",
    "\n",
    "bytes_gateway_model = converter.convert()\n",
    "with open('gateway_model.tflite', 'wb') as f:\n",
    "    f.write(bytes_gateway_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor Model\n",
    "Finally, we train a model to be deployed on the ESP32 microcontroller. Given the minimal computational resources available on the ESP32, the model needs to be extremely lightweight. Therefore, we simplify the model architecture by employing only `Conv1D` layers and reducing the number of neurons in the fully connected layers. The optimizations for the sensor model go beyond those used for the gateway model. In addition to **pruning**, the model is quantized using **full integer quantization**. This type of quantization converts both the weights and activations of the model from 32-bit floating-point numbers to 8-bit integers. Full integer quantization is more aggressive than dynamic range quantization, but it requires calibrating the quantization parameters using a representative dataset. The calibration dataset is generated by sampling a subset of the training data. It is important to note that LSTM layers are not used in the sensor model because they are computationally expensive and are not included in TensorFlow Lite's `TFLITE_BUILTINS_INT8` operation set, which is required for full integer quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sensor model...\n",
      "Epoch 1/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.8728 - accuracy: 0.6717 - val_loss: 0.5244 - val_accuracy: 0.7951\n",
      "Epoch 2/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8300 - val_loss: 0.3817 - val_accuracy: 0.8366\n",
      "Epoch 3/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8774 - val_loss: 0.3100 - val_accuracy: 0.8842\n",
      "Epoch 4/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.9125 - val_loss: 0.2669 - val_accuracy: 0.9043\n",
      "Epoch 5/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9292 - val_loss: 0.2245 - val_accuracy: 0.9358\n",
      "Epoch 6/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9482 - val_loss: 0.2175 - val_accuracy: 0.9358\n",
      "Epoch 7/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9528 - val_loss: 0.1895 - val_accuracy: 0.9463\n",
      "Epoch 8/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.1311 - accuracy: 0.9608 - val_loss: 0.2007 - val_accuracy: 0.9506\n",
      "Epoch 9/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9664 - val_loss: 0.1852 - val_accuracy: 0.9450\n",
      "Epoch 10/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9697 - val_loss: 0.1728 - val_accuracy: 0.9611\n",
      "Epoch 11/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9735 - val_loss: 0.1681 - val_accuracy: 0.9594\n",
      "Epoch 12/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.9723 - val_loss: 0.1714 - val_accuracy: 0.9637\n",
      "Epoch 13/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9782 - val_loss: 0.1644 - val_accuracy: 0.9607\n",
      "Epoch 14/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9808 - val_loss: 0.1678 - val_accuracy: 0.9620\n",
      "Epoch 15/15\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9840 - val_loss: 0.1750 - val_accuracy: 0.9633\n",
      "Fine-tuning sensor model...\n",
      "Epoch 1/5\n",
      "108/108 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9787 - val_loss: 0.2238 - val_accuracy: 0.9502\n",
      "Epoch 2/5\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9712 - val_loss: 0.2413 - val_accuracy: 0.9305\n",
      "72/72 [==============================] - 0s 543us/step\n"
     ]
    }
   ],
   "source": [
    "SENSOR_MODEL_TRAIN_EPOCHS = 15\n",
    "SENSOR_FINE_TUNE_EPOCHS = 5\n",
    "\n",
    "# --- Sensor Model Training ---\n",
    "print(\"Training sensor model...\")\n",
    "sensor_model = tf.keras.Sequential([\n",
    "    # Input layer\n",
    "    tf.keras.layers.Input(shape=(SEQ_LENGTH, 6)),\n",
    "    \n",
    "    # Convolutional layers\n",
    "    tf.keras.layers.SeparableConv1D(filters=16, kernel_size=3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Dense layers\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(LABELS), activation='softmax')\n",
    "])\n",
    "\n",
    "callbakcs = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=MAX_EPOCHS_WITHOUT_IMPROVEMENT, restore_best_weights=True)\n",
    "]\n",
    "sensor_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "sensor_model.fit(X_train, y_train, epochs=SENSOR_MODEL_TRAIN_EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), callbacks=callbacks)\n",
    "\n",
    "# --- Sensor Model Fine-Tuning ---\n",
    "print(\"Fine-tuning sensor model...\")\n",
    "num_sequences = X_train.shape[0]\n",
    "end_step = np.ceil(num_sequences / BATCH_SIZE).astype(np.int32) * SENSOR_FINE_TUNE_EPOCHS\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.0,\n",
    "        final_sparsity=0.60,\n",
    "        begin_step=0,\n",
    "        end_step=end_step\n",
    "    )\n",
    "}\n",
    "\n",
    "fine_tuning_callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=MAX_EPOCHS_WITHOUT_IMPROVEMENT, restore_best_weights=False)\n",
    "]\n",
    "\n",
    "# Create a pruned model\n",
    "sensor_model = prune_low_magnitude(sensor_model, **pruning_params)\n",
    "\n",
    "# Compile the pruned model\n",
    "sensor_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune with pruning\n",
    "sensor_model.fit(X_train, y_train, epochs=SENSOR_FINE_TUNE_EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), callbacks=fine_tuning_callbacks)\n",
    "\n",
    "# Evaluate the model\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "sensor_y_pred = sensor_model.predict(X_test)\n",
    "sensor_y_pred_classes = np.argmax(sensor_y_pred, axis=1)\n",
    "sensor_model_accuracy = np.sum(y_true == sensor_y_pred_classes) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.94      0.89      0.91       517\n",
      "  Acceptable       0.97      0.99      0.98       635\n",
      "Unacceptable       0.96      0.93      0.95       748\n",
      "         Bad       0.91      0.98      0.94       389\n",
      "\n",
      "    accuracy                           0.95      2289\n",
      "   macro avg       0.94      0.95      0.95      2289\n",
      "weighted avg       0.95      0.95      0.95      2289\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[462   8  23  24]\n",
      " [  1 631   3   0]\n",
      " [ 24  14 697  13]\n",
      " [  6   0   3 380]]\n",
      "Sensor model accuracy: 0.9480122324159022\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_separa  (None, 50, 16)            228       \n",
      " ble_conv1d_4 (PruneLowMagn                                      \n",
      " itude)                                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_max_po  (None, 25, 16)            1         \n",
      " oling1d_2 (PruneLowMagnitu                                      \n",
      " de)                                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_flatte  (None, 400)               1         \n",
      " n_4 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 16)                12818     \n",
      " 8 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 16)                530       \n",
      " 9 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 4)                 134       \n",
      " 10 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13712 (53.59 KB)\n",
      "Trainable params: 6886 (26.90 KB)\n",
      "Non-trainable params: 6826 (26.69 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(\"--- Classification Report ---\")\n",
    "print(classification_report(y_true, sensor_y_pred_classes, target_names=LABELS.keys()))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"--- Confusion Matrix ---\")\n",
    "print(confusion_matrix(y_true, sensor_y_pred_classes))\n",
    "\n",
    "# Print accuracy before tflite conversion\n",
    "print(f\"Sensor model accuracy: {sensor_model_accuracy}\")\n",
    "\n",
    "# Print the sensor model summary\n",
    "sensor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/cv/np29wc5x57scn_0hl8328btr0000gn/T/tmp8nuy8pon/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/cv/np29wc5x57scn_0hl8328btr0000gn/T/tmp8nuy8pon/assets\n",
      "/Users/rdelaf/Documents/thesis/edge-sensor-network/esn-cloud-layer/model/venv/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:947: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "# Remove pruning wrappers from the pruned model\n",
    "sensor_model = tfmot.sparsity.keras.strip_pruning(sensor_model)\n",
    "\n",
    "# Representative dataset for quantization\n",
    "def representative_dataset():\n",
    "    for i in range(0, X_train.shape[0], BATCH_SIZE):\n",
    "        yield [X_train[i:i + BATCH_SIZE]]\n",
    "\n",
    "# Make a Tensorflow Lite version of the model and save it\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(sensor_model)\n",
    "\n",
    "# Full integer quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "bytes_sensor_model = converter.convert()\n",
    "with open('sensor_model.tflite', 'wb') as f:\n",
    "    f.write(bytes_sensor_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison\n",
    "Below me compare the performance of the cloud, gateway, and sensor models in terms of accuracy and size. The accuracy is evaluated using the test set, while the size is measured in terms of the compressed model file size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size comparison\n",
    "def get_gzipped_model_size(file):\n",
    "  import os, zipfile, tempfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "  return os.path.getsize(zipped_file)\n",
    "\n",
    "def format_size(size_bytes):\n",
    "    if size_bytes < 1024:\n",
    "        return f\"{size_bytes:.2f} bytes\"\n",
    "    elif size_bytes < 1024 ** 2:\n",
    "        return f\"{size_bytes / 1024:.2f} KB\"\n",
    "    else:\n",
    "        return f\"{size_bytes / 1024 ** 2:.2f} MB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy comparison\n",
    "def _quantize_model(input_data, input_details):\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    input_data = input_data / input_scale + input_zero_point\n",
    "    return input_data\n",
    "\n",
    "\n",
    "def evaluate_tflite_model(tflite_model_path, X_test, y_test):\n",
    "    # Load the TFLite model and allocate tensors\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensor details\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        # Check if the input type is quantized, then rescale input data to uint8\n",
    "        input_data = _quantize_model(X_test[i], input_details) if input_details['dtype'] == np.uint8 else X_test[i]\n",
    "\n",
    "        input_data = np.expand_dims(input_data, axis=0).astype(input_details['dtype'])   \n",
    "        interpreter.set_tensor(input_details['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details['index'])\n",
    "        \n",
    "        predicted_label = np.argmax(output_data)\n",
    "\n",
    "\n",
    "        true_label = np.argmax(y_test[i])\n",
    "\n",
    "        if predicted_label == true_label:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    return correct_predictions / X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
      "INFO: TfLiteFlexDelegate delegate: 2 nodes delegated out of 27 nodes with 2 partitions.\n",
      "\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(sequences, labels, test_size=0.4, random_state=random.randint(0, 100))\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random.randint(0, 100))\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(LABELS))\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=len(LABELS))\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(LABELS))\n",
    "\n",
    "cloud_size = get_gzipped_model_size(\"cloud_model.keras\")\n",
    "gateway_size = get_gzipped_model_size(\"gateway_model.tflite\")\n",
    "sensor_size = get_gzipped_model_size(\"sensor_model.tflite\")\n",
    "\n",
    "tflite_gateway_model_accuracy = evaluate_tflite_model('gateway_model.tflite', X_test, y_test)\n",
    "tflite_sensor_model_accuracy = evaluate_tflite_model('sensor_model.tflite', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- Model Sizes ----------------------\n",
      "Size of cloud Keras model: 7.49 MB\n",
      "Size of gateway Tflite model: 653.15 KB\n",
      "Size of sensor Tflite model: 13.08 KB\n",
      "\n",
      "---------------------- Gzipped Model Sizes ----------------------\n",
      "Size of gzipped cloud Keras model: 6.87 MB\n",
      "Size of gzipped gateway Tflite model: 395.83 KB\n",
      "Size of gzipped sensor Tflite model: 7.92 KB\n",
      "\n",
      "---------------------- Model Size Comparison ----------------------\n",
      "Gateway model is 17.78 times smaller than the cloud model\n",
      "Sensor model is 887.85 times smaller than the cloud model\n",
      "Sensor model is 49.95 times smaller than the gateway model\n",
      "\n",
      "---------------------- Model Accuracies ----------------------\n",
      "Cloud model accuracy: 98.08% [Tensorflow Keras]\n",
      "Gateway model accuracy: 97.34% [TensorFlow Lite]\n",
      "Sensor model accuracy: 94.58% [TensorFlow Lite Micro]\n"
     ]
    }
   ],
   "source": [
    "# Print the model sizes\n",
    "print(\"\\n---------------------- Model Sizes ----------------------\")\n",
    "print(\"Size of cloud Keras model: %s\" % format_size(os.path.getsize(\"cloud_model.keras\")))\n",
    "print(\"Size of gateway Tflite model: %s\" % format_size(os.path.getsize(\"gateway_model.tflite\")))\n",
    "print(\"Size of sensor Tflite model: %s\" % format_size(os.path.getsize(\"sensor_model.tflite\")))\n",
    "\n",
    "print(\"\\n---------------------- Gzipped Model Sizes ----------------------\")\n",
    "print(\"Size of gzipped cloud Keras model: %s\" % format_size(cloud_size))\n",
    "print(\"Size of gzipped gateway Tflite model: %s\" % format_size(gateway_size))\n",
    "print(\"Size of gzipped sensor Tflite model: %s\" % format_size(sensor_size))\n",
    "\n",
    "# Print how much smaller the gateway model is\n",
    "print(\"\\n---------------------- Model Size Comparison ----------------------\")\n",
    "print(\"Gateway model is %.2f times smaller than the cloud model\" % (get_gzipped_model_size(\"cloud_model.keras\") / get_gzipped_model_size(\"gateway_model.tflite\")))\n",
    "print(\"Sensor model is %.2f times smaller than the cloud model\" % (get_gzipped_model_size(\"cloud_model.keras\") / get_gzipped_model_size(\"sensor_model.tflite\")))\n",
    "print(\"Sensor model is %.2f times smaller than the gateway model\" % (get_gzipped_model_size(\"gateway_model.tflite\") / get_gzipped_model_size(\"sensor_model.tflite\")))\n",
    "\n",
    "# Print the model accuracies\n",
    "print(\"\\n---------------------- Model Accuracies ----------------------\")\n",
    "print(f\"Cloud model accuracy: {cloud_model_accuracy * 100:.2f}% [Tensorflow Keras]\")\n",
    "print(f\"Gateway model accuracy: {tflite_gateway_model_accuracy * 100:.2f}% [TensorFlow Lite]\")\n",
    "print(f\"Sensor model accuracy: {tflite_sensor_model_accuracy * 100:.2f}% [TensorFlow Lite Micro]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
